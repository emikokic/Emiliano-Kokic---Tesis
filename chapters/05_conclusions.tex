\chapter{Conclusiones y trabajo futuro} \label{chapter:chapter5}

\section{Conclusiones}

Una de las primeras problemáticas estudiadas fue la representación vectorial de una palabra dada su semántica en el contexto en el cual ocurre. La estrategia de decaimiento exponencial es la que mejor performa por sobre el resto de estrategias propuestas en el trabajo de \cite{iacobacci-etal-2016-embeddings}. Ponderar en mayor medida a las palabras inmediatamente cercanas a la palabra objetivo tiene sentido, ya que en general aporta mayor información que una palabra distante.

A lo largo del trabajo también se experimentaron modelos basados en redes convolucionales, con el afán de capturar información del contexto de cada palabra al aplicar capas convolucionales. Los resultados determinaron que aplicar convoluciones para extraer características del entorno de una palabra es una alternativa exitosa que supera a la estrategia de decaimiento exponencial.

Al incorporar la tarea no supervisada que proponen las redes neuronales en escalera se observó en distintos experimentos una mayor generalización de estos modelos respecto a los netamente supervisados. Esta mayor generalización puede ser consecuencia de haber compartido las representaciones ocultas de la red entre más de una tarea. 

Agregar una cierta cantidad de datos no anotados al entrenamiento del modelo de redes convolucionales en amplitud en escalera parece ser clave para mejorar el rendimiento del mismo. Sin embargo, se debe tener cuidado de no excederse ya que la red puede no ser lo suficientemente capaz de realizar la tarea no supervisada de reconstrucción de tantos datos no anotados y afectar negativamente al modelo en cuestión. A su vez, es importante regular el peso que se le asigna a la función de costo no supervisada. Si se excede, el modelo diverge ya que se centra demasiado en la tarea de reconstrucción dejando de lado la tarea supervisada de clasificación.

Sobre el modelo de redes convolucionales en profundidad se observó que entrenando el modelo con la totalidad de instancias de entrenamiento y utilizando solo un 25\% se obtienen resultados similares. Vemos entonces la ventaja de trabajar con este modelo semi-supervisado donde tomar una proporción significativamente menor de datos no se corresponde con una gran pérdida de desempeño.

Finalmente, comparando los mejores resultados de cada modelo concluimos los modelos supervisados superan a sus variantes en escalera y que la arquitectura del modelo de redes convolucionales en amplitud tiene mejor desempeño que el modelo de redes convolucionales en profundidad.

\section{Trabajo futuro}

Una metodología interesante para la representación de palabras son los modelos de embeddings de caracteres, en donde el vector representante de una palabra se construye a partir de los \textit{n-grams} de caracteres que la componen. Dado que los caracteres son compartidos entre palabras, estos modelos de \textit{character embeddings} funcionan mejor para representar palabras que están fuera del vocabulario en cuestión. En contraste, modelos de \textit{word embeddings}, como por ejemplo el modelo Word2Vec utilizado en este trabajo de tesis no pueden representar una palabra fuera del vocabulario ya que tratan a cada palabra de forma atómica. Otro aspecto a tener en cuenta es que los modelos de \textit{character embeddings} tienden a generar mejores representaciones para aquellas palabras que aparecen con poca frecuencia, ya que los \textit{n-grams} de caracteres que se comparten entre las palabras aún pueden aprender buenos embeddings. Por otro lado, los modelos de \textit{word embeddings} sufren la falta de oportunidad de entrenamientos suficientes para palabras poco frecuentes.

En el trabajo de \cite{WiNER-Ghaddar-Langlais} se evalúa el desempeño de distintos modelos sobre el conjunto de datos WiNER. En particular, el modelo LSTM-CRF del trabajo de \cite{DBLP:journals/corr/HuangXY15} obtiene los mejores resultados. Este modelo combina el modelo LSTM (Long Short-Term Memory), una red neuronal del tipo recurrente y el método de modelado estadístico CRF (Conditional Random Field). Ambos modelos pertenecen a la familia de modelado de secuencias ya que por su composición les permite lidiar con problemas de series temporales. Surge entonces la idea de combinar las redes convolucionales en escalera estudiadas en este trabajo de tesis con el modelo LSTM-CRF donde el primero se utilizaría para la extracción de features y el segundo encargado de la tarea de clasificación.

Finalmente, como alternativa y en pos de conseguir mejores representaciones de palabras nos gustaría explorar modelos del estado del arte como ELMo (\textit{Embeddings from Language Models}) del trabajo de \cite{DBLP:journals/corr/abs-1802-05365} y BERT (\textit{Bidirectional Encoder Representations from Transformers}) del trabajo de \cite{DBLP:journals/corr/abs-1810-04805}.
